{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ad3e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f331d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_ai_integration_test.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f455da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/devwork/Developer/Project/resume-builder\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4031e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "189f6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Load environment variables from .env file using python-dotenv library\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv(\".env\") # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f61cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resume_optimizer.core.ats_optimizer.optimizer import ATSOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c551d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765268419.107666 10388863 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from resume_optimizer.core.ai_integration.gemini_client import GeminiClient\n",
    "\n",
    "gc = GeminiClient(os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4f42e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contact_info=ContactInfo(name='Ashish Surve', email='surve.ashish@outlook.com', phone='+91 70400 71239', address=None, linkedin='https://linkedin.com/in/ashish-surve', github='https://github.com/ashish-surve') summary='Product-focused Data Scientist with 6+ years building and shipping ML systems for CPG, retail and real-estate domains. Expert in demand forecasting, anomaly detection, and trade-promotion optimization — shipped production solutions that trained 300k models on multi-TB data and delivered $2.4M in client savings. Strong end-to-end ownership: problem framing, distributed model development (PySpark/Databricks), API deployment, monitoring, and stakeholder enablement.' skills=['Forecasting', 'Time Series', 'Anomaly Detection', 'Trade Promotion Optimization', 'Product ML', 'MLOps', 'Model Monitoring', 'Python', 'SQL', 'PySpark', 'Pandas', 'NumPy', 'scikit-learn', 'PyTorch', 'TensorFlow', 'FastAPI', 'Streamlit', 'Databricks', 'Spark', 'Dask', 'MongoDB', 'MySQL', 'Azure', 'AWS', 'Docker', 'CI/CD', 'Git', 'Hyperparameter tuning', 'Distributed training', 'RAG', 'Vector stores', 'OpenAI', 'Hugging Face', 'Semantic search', 'SHAP', 'PyOD', 'Vaex', 'Plotly', 'pre-commit'] experience=[Experience(company='Globant', position='Senior Data Scientist (Team Lead)', duration='May 2024 – Present', start_date='2024-05', end_date=None, description=['Led cross-functional delivery team (Big 4):Directed data science and engineering efforts, partnering with DevOps and solution architects to implement scalable, maintainable Data Engineering and ML best practices.', 'Enabled SaaS-readiness for payroll fraud detection:Architected end-to-end, cloud-agnostic ML and data pipelines to support a future SaaS offering; reduced development time for new clients by40%.', 'Built configurable anomaly detection platform:Delivered a multi-algorithm, config-driven system integrated with client front-end/back-end stacks to reduce manual intervention and simplify onboarding.', 'Innovated correlation-based detection:Implemented PySpark modules for payroll-component correlation analysis to improve anomaly discrimination and robustness across payroll complexities.', 'Ensured cloud vendor-independence:Engineered portable pipelines and orchestration usingAzure ML, Synapse, Prefect, Docker, Azure Functions, AWS SageMaker, enabling multi-cloud deployment options for clients.', 'Technologies: Python, PySpark, SQL, Azure ML, Synapse, Prefect, Docker, Azure Functions, AWS SageMaker, Azure SDK v2'], skills_used=[]), Experience(company='Tiger Analytics', position='Data Scientist (Project Lead)', duration='May 2021 – May 2024', start_date='2021-05', end_date='2024-05', description=['Demand Forecasting Accelerator: Designed and productionized a PySpark-based forecasting accelerator (Databricks) with a0.94 parallelization factorused across 20+ projects. Reduced model development and de- ployment time from weeks to days and standardized configuration-driven deployments.', 'Out-of-Stock Prevention (US):Led a production solution that trained300,000 modelsover a2TB dataset with auto- mated backtesting and HPO; outcome:$2.4M cost avoidance by reducing stockouts and expiry losses. Built simplified forecast views for non-technical managers.', 'Out-of-Stock Prevention (Russia): Headed implementation for a major CPG client; engineered50,000 models achieving 84% accuracy on high-quality segments and introduced feature-engineering strategies to improve low-quality data performance. Implemented Temporal Fusion Transformer for cross-learning and gained+17% uplift vs previous top models.', 'Anomaly Detection Accelerator:Co-developed a time-series anomaly detection system with automatic root-cause analysis (RCA) that reduced manual triage and improved incident response for supply-chain signals.', 'Trade Promotion Optimization (UK):Built a TPO tool with scenario planning and profit-pool dashboards to identify historically successful promotions and recommend future strategies per category.', 'Cashflow Forecasting:Led delivery of a cashflow forecasting pipeline to provide stakeholders with short-term financial visibility and scenario analysis for planning.', 'LLM Marketing Assistant:Prototyped an LLM + RAG agent to answer structured marketing queries for CMOs; inte- grated vector store retrieval and QA over tables — awarded 2nd place in internal hackathon.', 'Technologies: Python, PySpark, Databricks, TensorFlow, PyTorch, FastAPI, Streamlit, OpenAI, Hugging Face, RAG, SQL, Docker'], skills_used=[]), Experience(company='vCreaTek Consulting Services Pvt Ltd', position='Data Scientist & Developer', duration='Jun 2020 – May 2021', start_date='2020-06', end_date='2021-05', description=['Built Decision Support Systems for real-estate clients delivering KPIs and dashboards that informed strategic invest- ments and pricing decisions.', 'Led API Gateway and Developer Portal productionization (Golang + Looker) to enable external partners to consume internal APIs securely.', 'Automated repetitive data tasks and mentored junior engineers; earned RapidMiner Grandmaster recognition and 6 certifications.', 'Technologies: Golang, Looker, Python, RapidMiner, SQL'], skills_used=[]), Experience(company='Persistent Systems', position='Software Engineer Apprentice', duration='Jan 2020 – Jul 2020', start_date='2020-01', end_date='2020-07', description=['Led an 8-member team to deliver a COVID-19 pedestrian detection and homography-correction pipeline (computer vision) within one month; focused on rapid prototyping and production-readiness.', 'Completed industry certifications and internal exams (AI/ML fundamentals).', 'Technologies: Python, OpenCV, MTCNN, FaceNet'], skills_used=[]), Experience(company='IoTIoT.in', position='Artificial Intelligence Intern', duration='Sep 2019 – Jan 2020', start_date='2019-09', end_date='2020-01', description=['Implemented face-recognition pipeline using MTCNN + FaceNet and optimised inference pipelines for edge deploy- ment; achieved top rank in an AI-Python Hackerrank among IIT participants.', 'Technologies: MTCNN, FaceNet, Python'], skills_used=[])] education=[Education(institution='Dr. D. Y. Patil Institute of Technology, SPPU, Pune', degree='B.E.', field='Computer Science', graduation_date='', gpa=None, description=['First Class with Distinction', 'Relevant coursework: Machine Learning, Data Science Statistics, Big Data Analytics, Probability, Discrete Mathematics'])] certifications=['RapidMiner Grandmaster (6 certifications)', 'Microsoft AI/ML fundamentals'] languages=[] raw_text='Ashish Surve\\nć surve.ashish@outlook.com | Ħ +91 70400 71239\\na github.com/ashish-surve | ] linkedin.com/in/ashish-surve\\nSummary\\nProduct-focused Data Scientist with 6+ years building and shipping ML systems for CPG, retail and real-estate domains.\\nExpert in demand forecasting, anomaly detection, and trade-promotion optimization — shipped production solutions that\\ntrained 300k models on multi-TB data and delivered $2.4M in client savings. Strong end-to-end ownership: problem framing,\\ndistributed model development (PySpark/Databricks), API deployment, monitoring, and stakeholder enablement.\\nSkills\\nCore: Forecasting, Time Series, Anomaly Detection, Trade Promotion Optimization, Product ML, MLOps, Model Monitoring\\nLanguages & Frameworks:Python, SQL, PySpark, Pandas, NumPy, scikit-learn, PyTorch, TensorFlow, FastAPI, Streamlit\\nData & Infra: Databricks, Spark, Dask, MongoDB, MySQL, Azure, AWS, Docker, CI/CD, Git, Hyperparameter tuning,\\nDistributed training\\nNLP / LLMs:RAG, Vector stores, OpenAI, Hugging Face, Semantic search\\nTools: SHAP, PyOD, Vaex, Plotly, Streamlit, FastAPI, pre-commit\\nWork Experience\\nGlobant May 2024 – Present\\nSenior Data Scientist (Team Lead)\\n• Led cross-functional delivery team (Big 4):Directed data science and engineering efforts, partnering with DevOps\\nand solution architects to implement scalable, maintainable Data Engineering and ML best practices.\\n• Enabled SaaS-readiness for payroll fraud detection:Architected end-to-end, cloud-agnostic ML and data pipelines\\nto support a future SaaS offering; reduced development time for new clients by40%.\\n• Built configurable anomaly detection platform:Delivered a multi-algorithm, config-driven system integrated with\\nclient front-end/back-end stacks to reduce manual intervention and simplify onboarding.\\n• Innovated correlation-based detection:Implemented PySpark modules for payroll-component correlation analysis\\nto improve anomaly discrimination and robustness across payroll complexities.\\n• Ensured cloud vendor-independence:Engineered portable pipelines and orchestration usingAzure ML, Synapse,\\nPrefect, Docker, Azure Functions, AWS SageMaker, enabling multi-cloud deployment options for clients.\\n• Technologies: Python, PySpark, SQL, Azure ML, Synapse, Prefect, Docker, Azure Functions, AWS SageMaker, Azure\\nSDK v2\\nTiger Analytics May 2021 – May 2024\\nData Scientist (Project Lead)\\n• Demand Forecasting Accelerator: Designed and productionized a PySpark-based forecasting accelerator\\n(Databricks) with a0.94 parallelization factorused across 20+ projects. Reduced model development and de-\\nployment time from weeks to days and standardized configuration-driven deployments.\\n• Out-of-Stock Prevention (US):Led a production solution that trained300,000 modelsover a2TB dataset with auto-\\nmated backtesting and HPO; outcome:$2.4M cost avoidance by reducing stockouts and expiry losses. Built simplified\\nforecast views for non-technical managers.\\n• Out-of-Stock Prevention (Russia): Headed implementation for a major CPG client; engineered50,000 models\\nachieving 84% accuracy on high-quality segments and introduced feature-engineering strategies to improve low-\\nquality data performance. Implemented Temporal Fusion Transformer for cross-learning and gained+17% uplift vs\\nprevious top models.\\n• Anomaly Detection Accelerator:Co-developed a time-series anomaly detection system with automatic root-cause\\nanalysis (RCA) that reduced manual triage and improved incident response for supply-chain signals.\\n• Trade Promotion Optimization (UK):Built a TPO tool with scenario planning and profit-pool dashboards to identify\\nhistorically successful promotions and recommend future strategies per category.\\n• Cashflow Forecasting:Led delivery of a cashflow forecasting pipeline to provide stakeholders with short-term financial\\nvisibility and scenario analysis for planning.\\n• LLM Marketing Assistant:Prototyped an LLM + RAG agent to answer structured marketing queries for CMOs; inte-\\ngrated vector store retrieval and QA over tables — awarded 2nd place in internal hackathon.\\n• Technologies: Python, PySpark, Databricks, TensorFlow, PyTorch, FastAPI, Streamlit, OpenAI, Hugging Face, RAG,\\nSQL, Docker\\nvCreaTek Consulting Services Pvt Ltd Jun 2020 – May 2021\\nData Scientist & Developer\\n• Built Decision Support Systems for real-estate clients delivering KPIs and dashboards that informed strategic invest-\\nments and pricing decisions.\\n• Led API Gateway and Developer Portal productionization (Golang + Looker) to enable external partners to consume\\ninternal APIs securely.\\n• Automated repetitive data tasks and mentored junior engineers; earned RapidMiner Grandmaster recognition and 6\\ncertifications.\\n• Technologies: Golang, Looker, Python, RapidMiner, SQL\\nPersistent Systems Jan 2020 – Jul 2020\\nSoftware Engineer Apprentice\\n• Led an 8-member team to deliver a COVID-19 pedestrian detection and homography-correction pipeline (computer\\nvision) within one month; focused on rapid prototyping and production-readiness.\\n• Completed industry certifications and internal exams (AI/ML fundamentals).\\n• Technologies: Python, OpenCV, MTCNN, FaceNet\\nIoTIoT.in Sep 2019 – Jan 2020\\nArtificial Intelligence Intern\\n• Implemented face-recognition pipeline using MTCNN + FaceNet and optimised inference pipelines for edge deploy-\\nment; achieved top rank in an AI-Python Hackerrank among IIT participants.\\n• Technologies: MTCNN, FaceNet, Python\\nEducation\\nDr. D. Y. Patil Institute of Technology, SPPU, Pune B.E. Computer Science\\nFirst Class with Distinction\\nRelevant coursework: Machine Learning, Data Science Statistics, Big Data Analytics, Probability, Discrete Mathematics\\nSelected Projects\\n• Demand Forecasting Accelerator (github.com/ashish-surve): End-to-end forecasting framework that standardizes\\nconfig-driven model training, backtesting and deployment across multiple clients. Includes PySpark pipelines and\\nautomated HPO jobs.\\n• Out-of-Stock Prevention Demo:Repro notebook illustrating per-SKU forecasting with backtesting and scenario anal-\\nysis (links and docs on GitHub).\\n• LLM Marketing Assistant Prototype:RAG-based agent integrating vector store retrieval and structured-table QA to\\nsurface marketing insights to non-technical users.\\nAwards & Certifications\\n• RapidMiner Grandmaster (6 certifications)\\n• 2nd place — Tiger Analytics internal Hackathon (LLM Marketing Assistant)\\n• 1st rank — AI-Python Hackerrank (IoTIoT.in internship contest)\\n• Certifications: Microsoft AI/ML fundamentals (internal exams listed)' file_path=PosixPath('/Users/devwork/Developer/Project/resume-builder/data/input/resumes/!Lead Data Scientist Resume Ashish Surve 6.pdf') file_type=<FileType.PDF: 'pdf'> created_at=datetime.datetime(2025, 12, 9, 13, 50, 19, 132078)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# load resume data from a file \n",
    "from resume_optimizer.core.resume_parser import ResumeParserFactory\n",
    "\n",
    "parser = ResumeParserFactory.create_parser(gemini_client=gc)\n",
    "\n",
    "\n",
    "path_file = Path(os.getcwd(), 'data', 'input', 'resumes', '!Lead Data Scientist Resume Ashish Surve 6.pdf')\n",
    "resume_data = parser.parse(path_file)\n",
    "print(resume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573be813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3431a159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RapidMiner Grandmaster (6 certifications)', 'Microsoft AI/ML fundamentals']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_data.certifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c57c70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CERTIFICATIONS', ['RapidMiner Grandmaster (6 certifications)', 'Microsoft AI/ML fundamentals']]\n"
     ]
    }
   ],
   "source": [
    "if resume_data.certifications:\n",
    "    print([\"CERTIFICATIONS\", resume_data.certifications])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070bfca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f54a3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data = \"\"\"\n",
    "About the job\n",
    "Position Overview Job Title: Director: AI Tech Lead Location: Pune Job Summary\n",
    "\n",
    "We are seeking an experienced AI Technology Lead to lead our Artificial Intelligence(AI) strategy, development, and implementation across the function. The successful candidate will work in collaboration with other business functions and departments and will be responsible for designing, developing, and deploying AI solutions, which are in-line with bank’s AI strategy and which drive business value, improve operational efficiency, and enhance customer experience.\n",
    "\n",
    "What we’ll offer you:\n",
    "\n",
    "As part of our flexible scheme, here are just some of the benefits that you’ll enjoy\n",
    "\n",
    "Best in class leave policy\n",
    "Gender neutral parental leaves\n",
    "100% reimbursement under child care assistance benefit (gender neutral)\n",
    "Flexible working arrangements\n",
    "Sponsorship for Industry relevant certifications and education\n",
    "Employee Assistance Program for you and your family members\n",
    "Comprehensive Hospitalization Insurance for you and your dependents\n",
    "Accident and Term life Insurance\n",
    "Complementary Health screening for 35 yrs. and above\n",
    "\n",
    "\n",
    "Key Responsibilities: Strategic Planning and Leadership\n",
    "\n",
    "Develop and execute the AI strategy aligned with the bank's overall technology vision and objectives.\n",
    "Collaborate with cross-functional teams to identify opportunities for AI adoption and prioritize projects.\n",
    "Provide technical leadership and guidance to the AI development team.\n",
    "\n",
    "\n",
    "AI Development and Deployment\n",
    "\n",
    "Design, develop, and deploy AI models and algorithms that meet business requirements and regulatory standards.\n",
    "Lead the development of AI-powered solutions for various business domains, including P&L accounting, and process automation.\n",
    "Ensure seamless integration with existing systems and data platforms.\n",
    "\n",
    "\n",
    "Research and Innovation\n",
    "\n",
    "Stay up-to-date with the latest advancements in AI and machine learning (ML) technologies.\n",
    "Collaborate with other divisions and central AI teams to identify emerging trends and technologies that can benefit the division.\n",
    "Develop proof-of-concept projects and pilots to explore new AI applications.\n",
    "\n",
    "\n",
    "Data Management and Analytics\n",
    "\n",
    "Ensure data quality, security, and governance for AI model development and deployment.\n",
    "Collaborate with the data analytics team to develop and implement data-driven insights and recommendations.\n",
    "\n",
    "\n",
    "Regulatory Compliance and Risk Management\n",
    "\n",
    "Ensure that all AI solutions comply with regulatory requirements and industry standards.\n",
    "Conduct regular risk assessments to identify potential vulnerabilities and mitigate them proactively.\n",
    "\n",
    "\n",
    "Collaboration and Communication\n",
    "\n",
    "Collaborate with stakeholders across the organization to ensure alignment and buy-in for AI initiatives.\n",
    "Communicate technical results and recommendations to non-technical stakeholders through clear and concise language.\n",
    "\n",
    "\n",
    "Requirements Education and Experience\n",
    "\n",
    "Bachelor's or Master's degree in Computer Science, Mathematics, Statistics, or a related field.\n",
    "Minimum 5+ years of experience in AI, ML, or data science, with at least 2+ years in a leadership role.\n",
    "\n",
    "\n",
    "Technical Skills\n",
    "\n",
    "Proficiency in Python, R, or other programming languages.\n",
    "Experience with deep learning frameworks (e.g., TensorFlow, PyTorch).\n",
    "Familiarity with natural language processing (NLP) and LLM architecture.\n",
    "Knowledge of data management platforms (e.g., Hadoop, Spark, BQ, ADX).\n",
    "\n",
    "\n",
    "Leadership and Management\n",
    "\n",
    "Proven track record of leading high-performing teams and driving results-oriented projects.\n",
    "Experience with Agile methodologies and Scrum frameworks.\n",
    "Strong communication and interpersonal skills.\n",
    "\n",
    "\n",
    "Good to Have\n",
    "\n",
    "Certifications: Relevant certifications in Data Science, Analytics, etc.\n",
    "\n",
    "Industry Knowledge: Experience working in the financial services industry, preferably in a global bank setting.\n",
    "\n",
    "Cloud Computing: Familiarity with cloud computing platforms (e.g., GCP, AWS, Azure).\n",
    "\n",
    "If you are an AI expert looking for a challenging role that will drive innovation and growth, please submit your application.\n",
    "\n",
    "How We’ll Support You\n",
    "\n",
    "  Training and development to help you excel in your career \n",
    " Flexible working to assist you balance your personal priorities \n",
    " Coaching and support from experts in your team \n",
    " A culture of continuous learning to aid progression \n",
    " A range of flexible benefits that you can tailor to suit your needs \n",
    "\n",
    "\n",
    "About Us And Our Teams\n",
    "\n",
    "Please visit our company website for further information:\n",
    "\n",
    " https://www.db.com/company/company.htm \n",
    "\n",
    "We strive for a culture in which we are empowered to excel together every day. This includes acting responsibly, thinking commercially, taking initiative and working collaboratively.\n",
    "\n",
    "Together we share and celebrate the successes of our people. Together we are Deutsche Bank Group.\n",
    "\n",
    "We welcome applications from all people and promote a positive, fair and inclusive work environment.\n",
    "\"\"\"\n",
    "\n",
    "company_name = \"Deutsche Bank\"\n",
    "applicant_name = \"Ashish Surve\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a7c6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resume_optimizer.core.job_analyzer.analyzer import JobDescriptionAnalyzer\n",
    "\n",
    "ja = JobDescriptionAnalyzer()\n",
    "job_data = ja.analyze(job_data, company_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0301199f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Position Overview Job Title: Director: AI Tech Lead Location: Pune Job Summary'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_data.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "396d9adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765268419.394339 10388863 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "opt = ATSOptimizer(os.environ.get(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eabfc38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Experience(company='Globant', position='Senior Data Scientist (Team Lead)', duration='May 2024 – Present', start_date='2024-05', end_date=None, description=['Led cross-functional delivery team (Big 4):Directed data science and engineering efforts, partnering with DevOps and solution architects to implement scalable, maintainable Data Engineering and ML best practices.', 'Enabled SaaS-readiness for payroll fraud detection:Architected end-to-end, cloud-agnostic ML and data pipelines to support a future SaaS offering; reduced development time for new clients by40%.', 'Built configurable anomaly detection platform:Delivered a multi-algorithm, config-driven system integrated with client front-end/back-end stacks to reduce manual intervention and simplify onboarding.', 'Innovated correlation-based detection:Implemented PySpark modules for payroll-component correlation analysis to improve anomaly discrimination and robustness across payroll complexities.', 'Ensured cloud vendor-independence:Engineered portable pipelines and orchestration usingAzure ML, Synapse, Prefect, Docker, Azure Functions, AWS SageMaker, enabling multi-cloud deployment options for clients.', 'Technologies: Python, PySpark, SQL, Azure ML, Synapse, Prefect, Docker, Azure Functions, AWS SageMaker, Azure SDK v2'], skills_used=[]),\n",
       " Experience(company='Tiger Analytics', position='Data Scientist (Project Lead)', duration='May 2021 – May 2024', start_date='2021-05', end_date='2024-05', description=['Demand Forecasting Accelerator: Designed and productionized a PySpark-based forecasting accelerator (Databricks) with a0.94 parallelization factorused across 20+ projects. Reduced model development and de- ployment time from weeks to days and standardized configuration-driven deployments.', 'Out-of-Stock Prevention (US):Led a production solution that trained300,000 modelsover a2TB dataset with auto- mated backtesting and HPO; outcome:$2.4M cost avoidance by reducing stockouts and expiry losses. Built simplified forecast views for non-technical managers.', 'Out-of-Stock Prevention (Russia): Headed implementation for a major CPG client; engineered50,000 models achieving 84% accuracy on high-quality segments and introduced feature-engineering strategies to improve low-quality data performance. Implemented Temporal Fusion Transformer for cross-learning and gained+17% uplift vs previous top models.', 'Anomaly Detection Accelerator:Co-developed a time-series anomaly detection system with automatic root-cause analysis (RCA) that reduced manual triage and improved incident response for supply-chain signals.', 'Trade Promotion Optimization (UK):Built a TPO tool with scenario planning and profit-pool dashboards to identify historically successful promotions and recommend future strategies per category.', 'Cashflow Forecasting:Led delivery of a cashflow forecasting pipeline to provide stakeholders with short-term financial visibility and scenario analysis for planning.', 'LLM Marketing Assistant:Prototyped an LLM + RAG agent to answer structured marketing queries for CMOs; inte- grated vector store retrieval and QA over tables — awarded 2nd place in internal hackathon.', 'Technologies: Python, PySpark, Databricks, TensorFlow, PyTorch, FastAPI, Streamlit, OpenAI, Hugging Face, RAG, SQL, Docker'], skills_used=[]),\n",
       " Experience(company='vCreaTek Consulting Services Pvt Ltd', position='Data Scientist & Developer', duration='Jun 2020 – May 2021', start_date='2020-06', end_date='2021-05', description=['Built Decision Support Systems for real-estate clients delivering KPIs and dashboards that informed strategic invest- ments and pricing decisions.', 'Led API Gateway and Developer Portal productionization (Golang + Looker) to enable external partners to consume internal APIs securely.', 'Automated repetitive data tasks and mentored junior engineers; earned RapidMiner Grandmaster recognition and 6 certifications.', 'Technologies: Golang, Looker, Python, RapidMiner, SQL'], skills_used=[]),\n",
       " Experience(company='Persistent Systems', position='Software Engineer Apprentice', duration='Jan 2020 – Jul 2020', start_date='2020-01', end_date='2020-07', description=['Led an 8-member team to deliver a COVID-19 pedestrian detection and homography-correction pipeline (computer vision) within one month; focused on rapid prototyping and production-readiness.', 'Completed industry certifications and internal exams (AI/ML fundamentals).', 'Technologies: Python, OpenCV, MTCNN, FaceNet'], skills_used=[]),\n",
       " Experience(company='IoTIoT.in', position='Artificial Intelligence Intern', duration='Sep 2019 – Jan 2020', start_date='2019-09', end_date='2020-01', description=['Implemented face-recognition pipeline using MTCNN + FaceNet and optimised inference pipelines for edge deploy- ment; achieved top rank in an AI-Python Hackerrank among IIT participants.', 'Technologies: MTCNN, FaceNet, Python'], skills_used=[])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_data.experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0e88ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 8.067371s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 8\n",
      "}\n",
      "].\n",
      "Gemini API call failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 5.878438329s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "]\n",
      "Failed to batch optimize experiences with Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 5.878438329s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "]\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 5.576008666s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "].\n",
      "Gemini API call failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 3.451962811s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "]\n",
      "Failed to optimize experience description with Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 3.451962811s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "]\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 3.146333766s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "].\n",
      "Gemini API call failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 1.020014359s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 1\n",
      "}\n",
      "]\n",
      "Failed to optimize experience description with Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 1.020014359s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 1\n",
      "}\n",
      "]\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 731.547068ms. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "].\n",
      "Gemini API call failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 58.530062848s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "]\n",
      "Failed to optimize experience description with Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 58.530062848s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "]\n",
      "Rate limit: waiting 5.11s for minute quota\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 53.312491031s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "].\n",
      "Gemini API call failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 51.198112974s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "]\n",
      "Failed to optimize experience description with Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 51.198112974s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "]\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 50.89943284s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 50\n",
      "}\n",
      "].\n",
      "Gemini API call failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 48.692869432s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 48\n",
      "}\n",
      "]\n",
      "Failed to optimize experience description with Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 48.692869432s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 48\n",
      "}\n",
      "]\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 48.406666931s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 48\n",
      "}\n",
      "].\n",
      "Gemini API call failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 46.252892556s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "]\n",
      "Failed to enhance skills with Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 46.252892556s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "]\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 45.954027783s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 45\n",
      "}\n",
      "].\n",
      "Gemini API call failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 43.776135054s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 43\n",
      "}\n",
      "]\n",
      "Failed to generate recommendations with Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 43.776135054s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 43\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "res = opt.optimize(resume_data=resume_data,\n",
    "             job_data=job_data,\n",
    "             applicant_name=applicant_name,\n",
    "             company_name=company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87ae2625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RapidMiner Grandmaster (6 certifications)', 'Microsoft AI/ML fundamentals']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.optimized_resume.certifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab81241a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.pdf'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from resume_optimizer.core.pdf_generator.generator import PDFGeneratorFactory\n",
    "\n",
    "gen = PDFGeneratorFactory().create_generator()\n",
    "\n",
    "gen.generate_pdf(res.optimized_resume,res, \"test.pdf\",\"Ashish Surve\",\"Globant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76369fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdcce19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848c99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d8273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-builder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
